<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Data Bodies - Hanif Hashim</title>
    <link rel="stylesheet" href="styles.css">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Crimson+Pro:wght@300;400;600&family=Inter:wght@300;400;500&display=swap" rel="stylesheet">
</head>
<body>
    <div class="page-wrapper">
        <aside class="sidebar">
            <div class="sidebar-content">
                <h1 class="site-name"><a href="index.html">Hanif Hashim</a></h1>
                <p class="site-tagline">Interactive media artist and creative technologist.</p>

                <nav class="main-nav">
                    <a href="index.html" class="nav-link">Featured</a>
                    
                    <a href="about.html" class="nav-link">About</a>
                    <a href="contact.html" class="nav-link">Contact</a>
                </nav>
            </div>

            <footer class="sidebar-footer">
                <p>&copy; 2025 Abdul Hanif Hashim</p>
            </footer>
        </aside>

        <main class="main-content">
            <article class="case-study">
                <div class="case-study-hero">
                    <img src="images/data-bodies-5.jpg" alt="Data Bodies installation">
                </div>

                <div class="case-study-header">
                    <div class="case-study-title">
                        <h1>Data Bodies</h1>
                        <p class="case-study-tagline">Interactive Experiential Installation</p>
                    </div>
                    <div class="case-study-meta">
                        <div class="meta-item">
                            <span class="meta-label">Role</span>
                            <span class="meta-value">Interactive Designer & Developer</span>
                        </div>
                        <div class="meta-item">
                            <span class="meta-label">Year</span>
                            <span class="meta-value">2025</span>
                        </div>
                        <div class="meta-item">
                            <span class="meta-label">Technologies</span>
                            <span class="meta-value">Motion Tracking, ML, Real-time Graphics</span>
                        </div>
                    </div>
                </div>

                <div class="case-study-section">
                    <h2 class="section-label">Challenge</h2>
                    <p class="section-content-large">How can physical spaces respond intelligently to human presence and movement to create memorable, personalized experiences?</p>
                </div>

                <div class="case-study-section">
                    <h2 class="section-label">Solution</h2>
                    <p class="section-content">An interactive installation that uses depth sensors and machine learning to transform visitor movement into responsive audiovisual environments. The system tracks multiple participants in real-time, adapting visual complexity and sound design based on occupancy, proximity, and gesture patterns.</p>
                </div>

                <div class="case-study-image">
                    <img src="images/data-bodies-setup.jpg" alt="Installation setup with Kinect sensor and display">
                    <p class="image-caption">Installation setup showing depth sensor tracking and real-time person detection</p>
                </div>

                <div class="case-study-image">
                    <img src="images/data-bodies-6.png" alt="Visual output">
                </div>

                <div class="case-study-section">
                    <h2 class="section-label">Key Features</h2>
                    <div class="features-grid">
                        <div class="feature">
                            <h3>Real-Time Motion Tracking</h3>
                            <p>Depth sensor technology tracks visitor positions, gestures, and movement patterns with low latency response</p>
                        </div>
                        <div class="feature">
                            <h3>Adaptive Complexity</h3>
                            <p>System scales from single-user to multi-user experiences, adjusting visual and sonic intensity dynamically</p>
                        </div>
                        <div class="feature">
                            <h3>Generative Content</h3>
                            <p>Machine learning models create unique audiovisual responses for each interaction session</p>
                        </div>
                        <div class="feature">
                            <h3>Spatial Intelligence</h3>
                            <p>Computer vision processes proximity, grouping, and flow patterns to inform experience design</p>
                        </div>
                    </div>
                </div>

                <div class="case-study-section">
                    <h2 class="section-label">Commercial Applications</h2>
                    <p class="section-content">The depth sensing and real-time processing capabilities developed for this project translate directly to commercial hospitality and experiential design applications. Below are two example implementations showing how the same technology creates business value:</p>
                </div>

                <div class="application-showcase">
                    <div class="application-card">
                        <div class="application-image">
                            <img src="images/touchless-checkin-flow.png" alt="Touchless check-in user journey">
                        </div>
                        <div class="application-content">
                            <h3>Hospitality: Touchless Check-In Experience</h3>
                            <p>Depth sensors enable contactless guest interactions from arrival to room entry. Guests trigger automated welcome sequences, access check-in information via gesture control, and receive personalized ambient responses—all without touching shared surfaces.</p>
                            <div class="application-benefits">
                                <span class="benefit-tag">Post-COVID Safety</span>
                                <span class="benefit-tag">Reduced Staff Load</span>
                                <span class="benefit-tag">Premium Guest Experience</span>
                            </div>
                        </div>
                    </div>

                    <div class="application-card">
                        <div class="application-image">
                            <img src="images/airbnb-guest-journey.png" alt="Smart Airbnb guest journey">
                        </div>
                        <div class="application-content">
                            <h3>Property Management: Automated Guest Journey</h3>
                            <p>Multi-unit property managers deploy depth sensing across common areas and individual units. The system detects guest arrival, adapts ambient conditions, monitors occupancy for analytics, and triggers turnover workflows—creating operational efficiency while enhancing the guest experience.</p>
                            <div class="application-benefits">
                                <span class="benefit-tag">Occupancy Analytics</span>
                                <span class="benefit-tag">Energy Optimization</span>
                                <span class="benefit-tag">Automated Workflows</span>
                            </div>
                        </div>
                    </div>
                </div>

                <div class="case-study-section">
                    <h3 style="font-size: 1.1rem; margin-bottom: 1rem; color: var(--text-primary);">Additional Use Cases</h3>
                    <ul class="application-list">
                        <li>Retail foot traffic analysis and layout optimization based on shopper movement patterns</li>
                        <li>Event check-in and queue management with real-time density monitoring</li>
                        <li>Museum exhibits that adapt content pacing to visitor flow and crowding levels</li>
                        <li>Corporate spaces with occupancy-aware lighting and HVAC for energy savings</li>
                    </ul>
                </div>

                <div class="case-study-image">
                    <img src="images/data-bodies-3.png" alt="System architecture">
                    <p class="image-caption">System architecture combining motion tracking, machine learning, and real-time content generation</p>
                </div>

                <div class="case-study-section">
                    <h2 class="section-label">Technical Stack</h2>
                    <div class="tech-stack">
                        <span class="tech-tag">Kinect Sensors</span>
                        <span class="tech-tag">MediaPipe</span>
                        <span class="tech-tag">Machine Learning</span>
                        <span class="tech-tag">Max/MSP</span>
                        <span class="tech-tag">Blender</span>
                        <span class="tech-tag">Real-time Graphics</span>
                    </div>
                </div>

                <div class="case-study-footer">
                    <p>Collaboration with Daniel Munoz C • CART398 Interactive Media Studio</p>
                </div>

                <a href="index.html" class="back-link">← Back to Projects</a>
            </article>
        </main>
    </div>
</body>
</html>
